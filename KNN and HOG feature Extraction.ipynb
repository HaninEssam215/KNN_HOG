{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "import numpy as np from collections import Counter from sklearn import datasets from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    " \n",
    "# Hog imports \n",
    " \n",
    "import os import cv2 from skimage.io import imread, imshow from skimage.feature import hog from skimage import exposure import numpy as np from tensorflow import keras \n",
    "from keras.datasets import cifar100 \n",
    " \n",
    " \n",
    "# Standard import \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import accuracy_score \n",
    " \n",
    " \n",
    "# loading dataset \n",
    " \n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine') \n",
    " \n",
    " \n",
    " \n",
    "# Hog Properties \n",
    "\n",
    "winSize=(32,32) blockSize=(8,8) blockStride=(4,4) cellSize=(4,4) \n",
    "nBins=9 \n",
    " \n",
    " \n",
    "# Hog Training Feature Extractions \n",
    " \n",
    " \n",
    "x_train_hog = [] \n",
    " \n",
    "for i in range(x_train.shape[0]): \n",
    "    image = x_train[i] \n",
    "    train_hog =  cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nBins)     train_hist = train_hog.compute(image)     x_train_hog.append(train_hist) \n",
    "x_train_hog = np.array(x_train_hog) \n",
    " \n",
    " \n",
    "# Printing the Training Feature Vector \n",
    "print(x_train_hog[0]) print(x_train_hog.shape) \n",
    " \n",
    " \n",
    "# Hog Testing Feature Extraction \n",
    "x_test_hog = [] \n",
    " \n",
    "for i in range(x_test.shape[0]):     image = x_test[i] \n",
    "    hog =  cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nBins)     hist = hog.compute(image)     x_test_hog.append(hist) \n",
    "     \n",
    "     \n",
    "x_test_hog = np.array(x_test_hog) \n",
    " \n",
    " \n",
    "# Printing the Testing Feature Vector \n",
    "\n",
    "print(x_train_hog[0]) \n",
    "print(x_train_hog.shape) \n",
    " \n",
    " \n",
    " \n",
    "def euclidean_distance( x1, x2 ): \n",
    "    return np.sqrt( np.sum(( x1 - x2) **2 ) ) \n",
    " \n",
    " \n",
    "# KNN CLASS \n",
    " \n",
    "\n",
    " \n",
    " \n",
    "class KNN:     def __init__(self, k=3): \n",
    "        self.k = k \n",
    "         \n",
    "    def fit(self, X, y): # x is my data sample & y is its label         self.X_train = X \n",
    "        self.y_train = y \n",
    "     \n",
    "    def predict(self, X):    # predict the testing samples         predicted_labels = [self._predict(x) for x in X]         return np.array(predicted_labels) \n",
    "     \n",
    "     \n",
    "    def _predict(self, x): \n",
    "         \n",
    "        # computing the distances between the x and all the examples in the training dataset 'X_train'         \n",
    "        distances = [euclidean_distance(x,x_train) for x_train in self.X_train]  # x_train is a training sample \n",
    "         \n",
    "        # Sort by distance and return indices of the first k neighbors         \n",
    "        k_idx = np.argsort(distances)[: self.k] \n",
    "         \n",
    "        # Extract the labels of the k nearest neighbor training samples         \n",
    "        k_neighbor_labels = [self.y_train[i] for i in k_idx] \n",
    "        #print(\"The k_neighbor_labels, name is of type:\", type(k_neighbor_labels)) \n",
    "         \n",
    "        # return the most common class label \n",
    "        most_common = Counter(k_neighbor_labels).most_common(1) # 1 the most common \n",
    "         \n",
    "        return most_common[0][0] #the value repeated the most then the no of times it was repeated \n",
    "         \n",
    "     \n",
    " \n",
    " \n",
    "# Using Standardized Feature Scaling  \n",
    " \n",
    "scaler = StandardScaler() \n",
    "x_train_hog = scaler.fit_transform(x_train_hog.astype(np.float32)) x_test_hog = scaler.transform(x_test_hog.astype(np.float32)) \n",
    " \n",
    " \n",
    "# Classifying the Hog Output by KNN & Printing the Accuracy \n",
    " \n",
    " \n",
    "classi = KNN( k = 91) \n",
    "classi.fit( x_train_hog[:10000], y_train[:10000].ravel()) predictions = classi.predict(x_test_hog[:2000]) accuracy = accuracy_score(y_test[:2000], predictions) print(accuracy) \n",
    " \n",
    " \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X , y , test_size=0.2, random_state=1234) #classi = KNN( k =11) \n",
    "#classi.fit( X_train, y_train) \n",
    "#predictions = classi.predict(X_test) \n",
    "#accuracy = accuracy_score(y_test , predictions) \n",
    "#print(accuracy) \n",
    " \n",
    " \n",
    "# In[ ]: \n",
    " \n",
    " \n",
    "#acc = np.sum(predictions == y_test ) / len(y_test) \n",
    "#accuracy = accuracy_score(y_test[:100], predictions) \n",
    "#print(X_train.shape) \n",
    "#print(X_train[8]) \n",
    "#print(acc) \n",
    "#print(accuracy) \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
